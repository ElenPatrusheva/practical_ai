{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.4.5)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from nltk) (1.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /apt/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /apt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower() #to lower case\n",
    "    # dealing with numbers (remmoving)\n",
    "    text = re.sub(r'[0-9]', ' ', text) # removing\n",
    "    # removing punctuations, accent marks and other diacritics\n",
    "    # also removes dots from abbreviations \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # remove unnecessery space symbols\n",
    "    text = re.sub(r'[\\s]+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def lemmatization(tokens):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    return [lemmatizer.lemmatize(i) for i in tokens]\n",
    "\n",
    "def full_preprocess(text):\n",
    "    text = preprocess(text)\n",
    "    tokens = tokenize(text)\n",
    "    tokens = lemmatization(tokens)\n",
    "    text = ' '.join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_parser(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.read().split('\\n');\n",
    "        texts = []\n",
    "        for l in lines:\n",
    "            z = re.match(r'\\d+\\.\\s*(?P<text>.*)', l)\n",
    "            tmp = z.group('text')\n",
    "            texts.append(tmp)\n",
    "        return texts\n",
    "texts = file_parser('data/facts.txt')\n",
    "corpus = [full_preprocess(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def make_DTM(texts):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    res = vectorizer.fit_transform(texts)\n",
    "    return res.todense(), vectorizer\n",
    "DTM, vect = make_DTM(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=105)\n",
    "latent = pca.fit_transform(DTM)\n",
    "pca.explained_variance_ratio_.sum()\n",
    "proj = pca.inverse_transform(latent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 105)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_process(query, vectorizer, pca):\n",
    "    query = full_preprocess(query)\n",
    "    vector = np.zeros(len(vectorizer.get_feature_names()))\n",
    "    '''\n",
    "    for t in query.split():\n",
    "        if t in vect.get_feature_names():\n",
    "    '''     \n",
    "    \n",
    "    counts = Counter(query.split())\n",
    "    for c in counts:\n",
    "        try:\n",
    "            vector[vectorizer.get_feature_names().index(c)] += counts[c]\n",
    "        except:\n",
    "            pass\n",
    "    vector = vector * vectorizer.idf_\n",
    "    compressed_q = pca.transform(vector.reshape(1, -1))\n",
    "    return compressed_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def search(latent, compressed_q):\n",
    "    values = cosine_similarity(latent, compressed_q).reshape(1, -1)[0]\n",
    "    args = values.argsort()[::-1]\n",
    "    ranking = pd.DataFrame()\n",
    "    for i in range(len(args)):\n",
    "        ranking.loc[i, 'Doc number'] = str(int(args[i]))\n",
    "        ranking.loc[i,'Content'] = texts[args[i]]\n",
    "        ranking.loc[i, 'Similarity'] = values[args[i]]\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc number</th>\n",
       "      <th>Content</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>It is physically impossible for pigs to look u...</td>\n",
       "      <td>0.823374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>In 1386 a pig in France was executed by public...</td>\n",
       "      <td>0.679172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148</td>\n",
       "      <td>It is impossible to sneeze with your eyes open.</td>\n",
       "      <td>0.151448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Guinness Book of Records holds the record for ...</td>\n",
       "      <td>0.078429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>The largest recorded snowflake was in Keogh, M...</td>\n",
       "      <td>0.072806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Doc number                                            Content  Similarity\n",
       "0         39  It is physically impossible for pigs to look u...    0.823374\n",
       "1          7  In 1386 a pig in France was executed by public...    0.679172\n",
       "2        148    It is impossible to sneeze with your eyes open.    0.151448\n",
       "3         40  Guinness Book of Records holds the record for ...    0.078429\n",
       "4          3  The largest recorded snowflake was in Keogh, M...    0.072806"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'pigs'\n",
    "compressed_q = query_process(query, vect, pca)\n",
    "ranking = search(latent, compressed_q)\n",
    "ranking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc number</th>\n",
       "      <th>Content</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>Cows kill more people than sharks do.</td>\n",
       "      <td>0.535209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>95% of people text things they could never say...</td>\n",
       "      <td>0.468248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>Blue-eyed people tend to have the highest tole...</td>\n",
       "      <td>0.468049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Every year more than 2500 left-handed people a...</td>\n",
       "      <td>0.436959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>About 150 people per year are killed by coconuts.</td>\n",
       "      <td>0.434098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Doc number                                            Content  Similarity\n",
       "0        112              Cows kill more people than sharks do.    0.535209\n",
       "1         37  95% of people text things they could never say...    0.468248\n",
       "2        101  Blue-eyed people tend to have the highest tole...    0.468049\n",
       "3        104  Every year more than 2500 left-handed people a...    0.436959\n",
       "4         45  About 150 people per year are killed by coconuts.    0.434098"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'people'\n",
    "compressed_q = query_process(query, vect, pca)\n",
    "ranking = search(latent, compressed_q)\n",
    "ranking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc number</th>\n",
       "      <th>Content</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>Of all the words in the English language, the ...</td>\n",
       "      <td>0.839905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>The word “gorilla” is derived from a Greek wor...</td>\n",
       "      <td>0.767241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>Bob Marley’s last words to his son before he d...</td>\n",
       "      <td>0.358859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122</td>\n",
       "      <td>Dogs are capable of understanding up to 250 wo...</td>\n",
       "      <td>0.333466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143</td>\n",
       "      <td>What is called a “French kiss” in the English-...</td>\n",
       "      <td>0.313644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Doc number                                            Content  Similarity\n",
       "0         97  Of all the words in the English language, the ...    0.839905\n",
       "1         58  The word “gorilla” is derived from a Greek wor...    0.767241\n",
       "2         29  Bob Marley’s last words to his son before he d...    0.358859\n",
       "3        122  Dogs are capable of understanding up to 250 wo...    0.333466\n",
       "4        143  What is called a “French kiss” in the English-...    0.313644"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'English words'\n",
    "compressed_q = query_process(query, vect, pca)\n",
    "ranking = search(latent, compressed_q)\n",
    "ranking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word “gorilla” is derived from a Greek word meaning, “A tribe of hairy women.”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(ranking[ranking['Doc number'] == '58']['Content'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yandex-translater in /usr/local/lib/python3.6/dist-packages (6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from yandex-translater) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->yandex-translater) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->yandex-translater) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->yandex-translater) (2.6)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->yandex-translater) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install yandex-translater\n",
    "import locale\n",
    "from yandex.Translater import Translater\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "\n",
    "api_key = open(\"yandex.translate.key\").read()   # todo your key in the file\n",
    "tr = Translater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(tr, x):\n",
    "    tr.set_text(x)\n",
    "    return tr.translate()\n",
    "\n",
    "def not_english_query_processing(q, langs, vect, pca, latent):\n",
    "    tr = Translater()\n",
    "    tr.set_key(api_key)\n",
    "    tr.set_to_lang('en')\n",
    "    tr.set_hint(*langs)\n",
    "    tr.set_text(q)\n",
    "    lang = tr.detect_lang()\n",
    "    print(lang)\n",
    "    result_query = tr.translate()\n",
    "    print(result_query)\n",
    "    compressed_q = query_process(result_query, vect, pca)\n",
    "    ranking = search(latent, compressed_q)\n",
    "    tr_inv = Translater()\n",
    "    tr_inv.set_key(api_key)\n",
    "    tr_inv.set_to_lang(lang)\n",
    "    tr_inv.set_from_lang('en')\n",
    "    translated = ranking[:6]\n",
    "    translated['Content'] = translated['Content'].apply(lambda x: translate(tr_inv, x))\n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru\n",
      "pigs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "result = not_english_query_processing('свиньи', ['ru', 'es', 'tt', 'en'], vect, pca, latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc number</th>\n",
       "      <th>Content</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Это физически невозможно для свиней, чтобы смо...</td>\n",
       "      <td>0.823374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>В 1386 г. свинья во Франции был казнен путем п...</td>\n",
       "      <td>0.679172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148</td>\n",
       "      <td>Невозможно чихнуть с открытыми глазами.</td>\n",
       "      <td>0.151448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Книге рекордов Гиннесса принадлежит рекорд за ...</td>\n",
       "      <td>0.078429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Самая большая зарегистрированная снежинка была...</td>\n",
       "      <td>0.072806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>143</td>\n",
       "      <td>То, что называется “французским поцелуем” в ан...</td>\n",
       "      <td>0.071106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Doc number                                            Content  Similarity\n",
       "0         39  Это физически невозможно для свиней, чтобы смо...    0.823374\n",
       "1          7  В 1386 г. свинья во Франции был казнен путем п...    0.679172\n",
       "2        148            Невозможно чихнуть с открытыми глазами.    0.151448\n",
       "3         40  Книге рекордов Гиннесса принадлежит рекорд за ...    0.078429\n",
       "4          3  Самая большая зарегистрированная снежинка была...    0.072806\n",
       "5        143  То, что называется “французским поцелуем” в ан...    0.071106"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
